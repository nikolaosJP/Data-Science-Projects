{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f5f506",
   "metadata": {},
   "source": [
    "<h3>Transfer Learning for Unsupervised Anomaly Detection</h3>\n",
    "\n",
    "![MVTEC Image](https://www.mvtec.com/fileadmin/_processed_/1/e/csm_dataset_overview_large_6f330dede4.png)\n",
    ">Image Source: https://www.mvtec.com/\n",
    "\n",
    "MVTec AD is an open access dataset (see [MVTec dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad)) used for training anomaly detection ML algorithms. It contains over 5.000 high-res images divided into 15 different objects, some of which are characterised by a morphological anomaly. These anomalies are manifested in a myriad of forms such as scratches, dents, or other structural irregularities.\n",
    "\n",
    "<h3>The goal of this project</h3>\n",
    "        \n",
    "- In this IPython notebook we will use Transfer Learning, a popular approach in deep learning, to firstly distinguish objects in pristine condition from those with anomalies and secondly to detect the exact location of any potential physical defects. Transfer Learning, in case you are unfamiliar with the concept, is a technique used to expediate the training period of deep convolutional neural networks. This is achieved by utilizing weights from pre-trained models that were developed for visual object recognition software research. Top performing models can be downloaded and used directly, or integrated into a new model to solve new tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef34d3",
   "metadata": {},
   "source": [
    "<h4>Step 1 - Import Modules and data subsets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1588d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprort standard modules\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import custom modules\n",
    "from python_utils.dataloader import get_train_test_loaders, get_cv_train_test_loaders\n",
    "from python_utils.model import CustomVGG\n",
    "from python_utils.helper import train, evaluate, predict_localize\n",
    "from python_utils.constants import NEG_CLASS\n",
    "\n",
    "# Change the current working directory to desired path.\n",
    "data_folder = os.getcwd()\n",
    "\n",
    "# Leave as is if you wish to analyze the 'carper' subset, or change it to 'capsule' if you want to analyze the capsule dataset\n",
    "subset_name = \"carpet\"\n",
    "\n",
    "data_folder = os.path.join(data_folder, subset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e69cc",
   "metadata": {},
   "source": [
    "<h4>Step 2 - Define the parameters of the model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9908d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "target_train_accuracy = 0.98\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "class_weight = [1, 3] \n",
    "\n",
    "heatmap_thres = 0.7\n",
    "n_cv_folds = 5\n",
    "\n",
    "# Move the device to \"GPU\" -if one is available- to expediate the analysis\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5948b",
   "metadata": {},
   "source": [
    "<h4>Step 3 - Run the dataloaders </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This custom function will splits dataset in stratified manner, considering various defect types.\n",
    "\n",
    "train_loader, test_loader = get_train_test_loaders(\n",
    "    root=data_folder, batch_size=batch_size, test_size=0.2, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6795b99",
   "metadata": {},
   "source": [
    "<h4>Step 4 - Train the model </h4>\n",
    "\n",
    "The custom-made model developed for this project is based on the VGG-16 architecture which had been pre-trained on ImageNet. The intermediary fully-connected neural network layers are replaced by an average global pooling layer and the last dense layer outputs a two-dimensional vector which is normalized and transformed into a probability distribution consisting of K probabilities ('Anomaly' for objects with structural irregularities or 'Good' otherwise). The loss-function for this model is based on cross-entropy and the optimizer is Adam with a learning rate of 0.0001. \n",
    "\n",
    "![Model Architrecture](https://user-images.githubusercontent.com/71797206/169629507-91206559-c316-40da-a129-d21b44931154.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf04f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomVGG()\n",
    "\n",
    "class_weight = torch.tensor(class_weight).type(torch.FloatTensor).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model = train(\n",
    "    train_loader, model, optimizer, criterion, epochs, device, target_train_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b583740",
   "metadata": {},
   "source": [
    "<h4>Step 5 - Perform cross-validationa and Evaluate the model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader, device)\n",
    "\n",
    "## Cross Validation\n",
    "cv_folds = get_cv_train_test_loaders(\n",
    "    root=data_folder,\n",
    "    batch_size=batch_size,\n",
    "    n_folds=n_cv_folds,\n",
    ")\n",
    "\n",
    "class_weight = torch.tensor(class_weight).type(torch.FloatTensor).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "\n",
    "for i, (train_loader, test_loader) in enumerate(cv_folds):\n",
    "    print(f\"Fold {i+1}/{n_cv_folds}\")\n",
    "    model = CustomVGG()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model = train(train_loader, model, optimizer, criterion, epochs, device)\n",
    "    evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7d4ac",
   "metadata": {},
   "source": [
    "<h4>Step 6 - Visualize the results </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28847fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs predictions for the samples in the dataloader and shows an image with its true label, predicted label and its probability.\n",
    "\n",
    "predict_localize(\n",
    "    model, test_loader, device, thres=heatmap_thres, n_samples=3, show_heatmap=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183f8ad",
   "metadata": {},
   "source": [
    "<h4> Final remarks</h4>\n",
    "\n",
    "The model was trained on two subsets of the MVTec Anomaly Detection Dataset, namely on the 'carpet' and 'capsule' sets. As depicted in the table below, the balanced accuracy of the model on an unseen dataset was close to 90% for both the carpet and capsule subsets, which is considered acceptable for the explorative nature of this project.\n",
    "\n",
    "Table 1: Summary of the findings \n",
    "    \n",
    "Subset Title | Test Accuracy | Balanced Test Accuracy | Confusion Matrix Labels |\n",
    "--- | --- | --- | --- |\n",
    "Carpet | 0.91 | 0.88 | TP = 57, TN = 15, FP = 3, FN = 4 |\n",
    "Capsule  | 0.93 | 0.91| TP = 46, TN = 19, FP = 3, FN = 2 |\n",
    "\n",
    "A simple illustration of the anomalies detected.\n",
    "\n",
    "![Findings](https://user-images.githubusercontent.com/71797206/169630481-6b613330-e16c-48b5-bb64-0db4e0dbee20.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
